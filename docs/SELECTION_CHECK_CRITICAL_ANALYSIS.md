# 당첨 확인 기능 구현 계획 - 비판적 분석 및 개선 제안

> 작성일: 2024-12-19  
> 분석 관점: 냉정하고 비판적인 기술 리뷰

---

## 🚨 심각한 문제점 (Critical Issues)

### 1. **Vercel 서버리스 환경에서 Puppeteer/Playwright 실행의 비현실성**

**문제점:**
- 문서는 "옵션 A: Node.js에서 직접 크롤링 (권장)"을 제안하지만, **Vercel은 서버리스 환경**입니다.
- Puppeteer/Playwright는 **무거운 브라우저 바이너리**를 필요로 하며, Vercel의 함수 크기 제한(50MB)과 실행 시간 제한(10초 Hobby, 60초 Pro)을 초과할 가능성이 매우 높습니다.
- 실제로 Puppeteer는 최소 100MB 이상의 크롬 바이너리를 포함하며, Vercel에서는 실행이 거의 불가능합니다.

**개선 방안:**
- **옵션 B(Python 크롤러 활용)를 재검토**하거나
- **별도 서버 인프라** (예: Railway, Render, AWS EC2) 사용
- 또는 **브라우저리스 크롤링** (Cheerio + HTTP 요청)으로 전환
- **Vercel Edge Functions**는 제한적이므로 고려하지 않음

**권장:**
```typescript
// 실제로는 HTTP 요청 + Cheerio 파싱이 현실적
// 또는 Python 크롤러를 별도 서버에서 실행하고 API로 호출
```

---

### 2. **일정 및 공수 추정의 과도한 낙관주의**

**문제점:**
- "리뷰노트 크롤러 완성: 2-3일" → **비현실적**
- "총 예상 기간: 4주 (20일)" → **최소 2배 이상 소요 예상**

**실제 소요 시간 분석:**
1. **리뷰노트 크롤러**: 
   - 네이버 로그인 세션 유지 로직: 1-2일
   - "내 신청 내역" 페이지 구조 분석: 1일
   - HTML 파싱 및 당첨 여부 판단 로직: 2-3일
   - 에러 처리 및 엣지 케이스: 2-3일
   - **실제 소요: 최소 6-8일**

2. **각 사이트별 크롤러**:
   - 사이트마다 구조가 완전히 다름
   - 로그인 방식, 세션 관리, HTML 구조 모두 상이
   - **각 사이트당 최소 3-5일** (문서는 1-2일로 추정)

3. **크롤러 API 실제 로직**:
   - 사이트별 분기 처리: 1일
   - 에러 핸들링: 2일
   - 테스트 및 디버깅: 3-5일
   - **실제 소요: 최소 6-8일**

**개선 방안:**
- **Phase 1만으로 최소 4-6주** 소요 예상
- MVP는 **1-2개 사이트만** 지원하는 것으로 범위 축소
- 나머지는 Phase 2로 연기

---

### 3. **네이버 세션 쿠키 관리의 보안 및 실현 가능성 문제**

**문제점:**
- `users.naver_session_cookies`에 쿠키를 저장하는 방식은:
  1. **보안 위험**: 쿠키는 민감한 인증 정보이며, DB에 평문 저장은 위험
  2. **세션 만료**: 네이버 세션은 보통 24시간 내 만료되며, 자동 갱신 불가능
  3. **쿠키 포맷**: 네이버 쿠키는 복잡한 구조이며, 단순 문자열 저장으로는 부족

**개선 방안:**
- **OAuth 2.0 방식**으로 네이버 API 연동 (하지만 네이버는 "내 신청 내역" API 제공 안 함)
- **사용자에게 주기적 재로그인 요청** (UX 저하)
- **세션 만료 감지 및 알림** 시스템 필수
- 쿠키는 **암호화하여 저장** (Supabase Vault 또는 환경 변수 활용)

---

### 4. **자동 당첨 확인 스케줄러의 리소스 및 비용 문제**

**문제점:**
- "신청 마감일 + 1일 후 자동 확인"은 **매일 수백~수천 건의 크롤링 요청**을 의미
- Vercel Cron은 **무료 플랜에서 제한적**이며, Pro 플랜도 비용 발생
- 각 크롤링이 10-30초 소요 시, **타임아웃 및 비용 폭증** 가능

**개선 방안:**
- **배치 처리**: 한 번에 최대 10-20건만 처리
- **우선순위 큐**: 사용자가 수동으로 확인한 적이 있는 신청 우선
- **재시도 로직**: 실패한 경우 다음 날 재시도
- **비용 모니터링**: Vercel 대시보드에서 함수 실행 시간 추적

---

### 5. **사이트별 크롤러 구현의 복잡도 과소평가**

**문제점:**
- 문서는 "공통 구현 패턴"을 제시하지만, **실제로는 각 사이트마다 완전히 다른 구조**:
  - 리뷰노트: Next.js 기반, `__NEXT_DATA__` 사용
  - 리뷰플레이스: 전통적인 서버 사이드 렌더링
  - 디너퀸: 다른 인증 방식
  - 각 사이트마다 "내 신청 내역" 페이지 구조가 완전히 다름

**개선 방안:**
- **사이트별 상세 분석 문서** 먼저 작성
- **프로토타입 구현** 후 공수 재추정
- **우선순위 재조정**: 사용자 수가 많은 1-2개만 Phase 1에서 구현

---

## ⚠️ 중간 수준 문제점 (Medium Issues)

### 6. **에러 처리 및 재시도 로직의 부재**

**문제점:**
- 문서에서 "재시도 로직"을 Phase 3으로 미루고 있음
- 하지만 크롤링은 **네트워크 오류, 타임아웃, 사이트 구조 변경** 등으로 자주 실패
- 재시도 없이는 **사용자 경험 크게 저하**

**개선 방안:**
- **Phase 1부터 재시도 로직 포함** (최소 3회 재시도, 지수 백오프)
- **에러 분류**: 네트워크 오류 vs 파싱 오류 vs 인증 오류
- **사용자 피드백**: 실패 시 명확한 에러 메시지

---

### 7. **테스트 전략의 부재**

**문제점:**
- 문서에 **테스트 계획이 전혀 없음**
- 크롤러는 사이트 구조 변경에 취약하므로, **자동화된 테스트 필수**

**개선 방안:**
- **통합 테스트**: 실제 사이트에 대한 E2E 테스트 (하지만 rate limiting 주의)
- **모의 데이터 테스트**: HTML 샘플을 저장하여 파싱 로직 테스트
- **회귀 테스트**: 사이트 구조 변경 감지 및 알림

---

### 8. **법적/윤리적 고려사항의 표면적 접근**

**문제점:**
- "robots.txt 준수", "과도한 요청 방지"만 언급
- 하지만 **실제로는 더 복잡한 법적 이슈** 존재:
  - 개인정보보호법: 사용자 쿠키 저장 및 활용
  - 서비스 약관 위반 가능성
  - 크롤링 금지 사이트 존재

**개선 방안:**
- **법무 검토**: 각 사이트의 이용약관 확인
- **사용자 동의**: 크롤링 사용에 대한 명시적 동의
- **Rate Limiting**: 요청 간 최소 2-3초 간격
- **User-Agent 명시**: 정당한 크롤러임을 표시

---

### 9. **성공 지표의 비현실성**

**문제점:**
- "리뷰노트 당첨 확인 성공률 80% 이상" → **과도하게 낙관적**
- 실제 크롤링 성공률은 **네트워크, 사이트 구조 변경, 세션 만료** 등으로 50-70% 수준

**개선 방안:**
- **초기 목표를 60%로 낮추고**, 점진적으로 개선
- **사용자 피드백 수집**: 수동 입력과 자동 확인 결과 비교
- **A/B 테스트**: 자동 확인 vs 수동 입력의 정확도 비교

---

### 10. **모니터링 및 알림 시스템 부재**

**문제점:**
- 크롤러 실패 시 **사용자나 개발자에게 알림이 없음**
- 사이트 구조 변경으로 크롤러가 깨져도 **몇 주 후에야 발견** 가능

**개선 방안:**
- **Sentry 또는 유사 도구**로 에러 모니터링
- **일일 크롤링 성공률 리포트** (이메일 또는 대시보드)
- **사이트 구조 변경 감지**: 파싱 실패율이 특정 임계값 초과 시 알림

---

## 💡 개선된 구현 계획 제안

### Phase 1 (MVP): 핵심 기능만 구현 (6-8주)

**목표:**
- **리뷰노트 1개 사이트만** 완벽하게 구현
- 수동 입력은 항상 가능하도록 유지
- 자동 확인은 "보조 기능"으로 포지셔닝

**구현 내용:**
1. **리뷰노트 크롤러 완성** (6-8일)
   - Python 크롤러 확장 (기존 크롤러 활용)
   - 별도 서버에서 실행 (Railway 또는 Render)
   - API로 호출

2. **크롤러 API 구현** (3-4일)
   - Python 크롤러 호출 엔드포인트
   - 에러 처리 및 재시도 로직

3. **세션 관리 개선** (2-3일)
   - 쿠키 암호화 저장
   - 세션 만료 감지 및 알림

4. **테스트 및 버그 수정** (5-7일)

**예상 기간: 3-4주**

---

### Phase 2: 확장 및 자동화 (4-6주)

**목표:**
- 추가 1-2개 사이트 지원
- 자동 확인 스케줄러 (제한적)

**구현 내용:**
1. **리뷰플레이스 크롤러** (5-7일)
2. **자동 확인 스케줄러** (3-4일)
   - 배치 처리 (한 번에 10건)
   - 우선순위 큐
3. **모니터링 시스템** (2-3일)
4. **테스트 및 최적화** (5-7일)

**예상 기간: 4-6주**

---

### Phase 3: 나머지 사이트 및 개선 (지속적)

**목표:**
- 나머지 사이트들 점진적 추가
- 성능 최적화
- 사용자 피드백 반영

---

## 📋 즉시 수정해야 할 사항

1. **기술 스택 재검토**
   - Puppeteer/Playwright → Python 크롤러 + 별도 서버
   - 또는 Cheerio + HTTP 요청 (브라우저 불필요)

2. **일정 재조정**
   - Phase 1: 3-4주 (기존 1주 → 3-4주)
   - 전체: 최소 8-12주 (기존 4주 → 8-12주)

3. **범위 축소**
   - Phase 1: 리뷰노트 1개만
   - 나머지는 Phase 2 이후

4. **보안 강화**
   - 쿠키 암호화 저장
   - 세션 만료 처리

5. **테스트 계획 추가**
   - 통합 테스트
   - 모의 데이터 테스트

6. **모니터링 시스템 추가**
   - 에러 추적
   - 성공률 모니터링

---

## 🎯 결론

원래 계획은 **과도하게 낙관적**이며, **기술적 제약사항을 충분히 고려하지 않았습니다**. 

**핵심 개선 사항:**
1. Vercel 서버리스 환경 제약 고려 → 별도 서버 또는 Python 크롤러 활용
2. 일정 현실화 → 최소 2배 이상 소요 예상
3. 범위 축소 → MVP는 1개 사이트만
4. 보안 및 법적 이슈 강화
5. 테스트 및 모니터링 필수

이러한 개선 없이는 프로젝트가 **중간에 막히거나 실패할 가능성이 높습니다**.
